{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QHnVupBBn9eR"
      },
      "source": [
        "# Introduction to Self-Driving Car Decision Making!\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "mKbML-MNWsin"
      },
      "source": [
        "#@title Run this for setup! (may take several minutes to finish all imports) Ignore any errors!\n",
        "# quiet dependency warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "!pip install -q pyyaml==5.1 &> /dev/null\n",
        "!pip install torch &> /dev/null\n",
        "!pip install 'git+https://github.com/facebookresearch/detectron2.git' &> /dev/null #takes up to 5 minutes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "-Gy0X47FWsiz"
      },
      "source": [
        "#@title Then run this for more setup!\n",
        "# check pytorch installation:\n",
        "import torch, torchvision\n",
        "#print(torch.__version__, torch.cuda.is_available())\n",
        "\n",
        "# Some basic setup:\n",
        "# Setup detectron2 logger\n",
        "import detectron2\n",
        "from detectron2.utils.logger import setup_logger\n",
        "setup_logger()\n",
        "\n",
        "# import some common libraries\n",
        "import numpy as np\n",
        "import os, json, cv2, random\n",
        "from google.colab.patches import cv2_imshow\n",
        "from skimage.transform import resize\n",
        "from PIL import Image\n",
        "from pandas import DataFrame\n",
        "from google.colab import data_table\n",
        "from tqdm import tqdm\n",
        "from ipywidgets import interact, IntSlider\n",
        "import time\n",
        "import pandas\n",
        "\n",
        "# import some common detectron2 utilities\n",
        "from detectron2 import model_zoo\n",
        "from detectron2.engine import DefaultPredictor\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
        "\n",
        "!wget -q --show-progress \"https://storage.googleapis.com/inspirit-ai-data-bucket-1/Data/AI%20Pioneers/Self%20Driving%20Cars/gtFine.zip\"\n",
        "!wget -q --show-progress \"https://storage.googleapis.com/inspirit-ai-data-bucket-1/Data/AI%20Pioneers/Self%20Driving%20Cars/leftImg8bit.zip\"\n",
        "!mkdir /content/gtFine/\n",
        "!mkdir /content/leftImg8bit/\n",
        "!mkdir /content/gtFine/train\n",
        "!mkdir /content/leftImg8bit/train\n",
        "\n",
        "!unzip -qo /content/gtFine.zip -d /content/gtFine/train && mv /content/gtFine/train/gtFine/* /content/gtFine/train && rm -rf /content/gtFine/train/gtFine /content/gtFine/train/__MACOSX\n",
        "!unzip -qo /content/leftImg8bit.zip -d /content/leftImg8bit/train && mv /content/leftImg8bit/train/leftImg8bit/* /content/leftImg8bit/train && rm -rf /content/leftImg8bit/train/leftImg8bit /content/leftImg8bit/train/__MACOSX\n",
        "\n",
        "X = []\n",
        "y = []\n",
        "\n",
        "for path in tqdm(sorted(os.listdir(\"/content/leftImg8bit/train\"))):\n",
        "  if path.endswith(\"png\"):\n",
        "    path = os.path.join('/content/leftImg8bit/train', path)\n",
        "    img = cv2.imread(path,cv2.IMREAD_COLOR)\n",
        "    img = cv2.resize(img,(512, 256))\n",
        "    X.append(img)\n",
        "\n",
        "for path in tqdm(sorted(os.listdir(\"/content/gtFine/train\"))):\n",
        "  if path.endswith(\"color.png\"):\n",
        "    path = os.path.join('/content/gtFine/train', path)\n",
        "    img = cv2.imread(path,cv2.IMREAD_COLOR)\n",
        "    img = cv2.resize(img,(512, 256))\n",
        "    y.append(img)\n",
        "\n",
        "X, input_data= np.array(X), np.array(X)\n",
        "y, output_data = np.array(y), np.array(y)\n",
        "\n",
        "class_list = ['person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'handbag', 'tie', 'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'bowl', 'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'keyboard', 'oven', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush']\n",
        "class_list = DataFrame(class_list, columns=['Class name'])\n",
        "\n",
        "output_label = ['GO!', 'GO!', 'GO!', 'GO!', 'GO!', 'GO!', 'GO!', 'GO!', 'GO!', 'GO!', 'GO!', 'STOP!', 'GO!', 'GO!', 'STOP!', 'STOP!', 'GO!', 'STOP!', 'GO!', 'GO!', 'STOP!', 'GO!', 'GO!', 'GO!', 'GO!', 'GO!', 'GO!', 'GO!', 'GO!', 'GO!', 'GO!', 'STOP!', 'GO!', 'GO!', 'GO!', 'STOP!', 'GO!', 'GO!', 'GO!', 'GO!', 'GO!', 'GO!', 'GO!', 'GO!', 'GO!', 'STOP!', 'STOP!', 'GO!', 'GO!', 'GO!', 'GO!', 'GO!', 'STOP!', 'GO!', 'GO!', 'GO!', 'GO!', 'GO!', 'GO!', 'GO!', 'GO!', 'STOP!', 'GO!', 'GO!', 'GO!', 'GO!', 'GO!', 'STOP!', 'GO!', 'GO!', 'GO!', 'GO!', 'GO!', 'GO!', 'STOP!', 'GO!', 'GO!', 'GO!', 'GO!', 'STOP!', 'GO!', 'GO!', 'GO!', 'GO!', 'GO!', 'GO!', 'GO!', 'STOP!', 'GO!', 'GO!', 'GO!', 'GO!', 'GO!', 'GO!', 'GO!', 'STOP!', 'GO!', 'GO!', 'GO!', 'GO!', 'GO!', 'GO!', 'STOP!', 'GO!', 'GO!', 'GO!', 'GO!', 'STOP!', 'STOP!', 'GO!', 'GO!', 'GO!', 'GO!', 'GO!', 'GO!', 'GO!', 'GO!', 'GO!', 'GO!', 'GO!', 'GO!', 'GO!', 'GO!', 'GO!', 'GO!', 'GO!', 'GO!', 'GO!', 'GO!', 'GO!', 'GO!', 'GO!', 'GO!', 'STOP!', 'STOP!', 'GO!', 'GO!', 'GO!', 'GO!', 'GO!', 'GO!', 'GO!', 'GO!', 'GO!', 'GO!', 'GO!', 'GO!', 'GO!', 'GO!', 'GO!', 'GO!', 'GO!', 'GO!', 'GO!', 'GO!', 'STOP!', 'GO!', 'GO!', 'GO!', 'GO!', 'GO!', 'GO!', 'GO!', 'GO!', 'STOP!', 'GO!', 'GO!', 'STOP!', 'GO!', 'GO!', 'STOP!', 'STOP!', 'STOP!', 'STOP!', 'GO!', 'GO!', 'GO!', 'GO!', 'GO!', 'GO!', 'STOP!', 'GO!', 'GO!', 'STOP!', 'GO!', 'GO!', 'STOP!', 'GO!', 'GO!', 'GO!', 'GO!', 'GO!', 'STOP!', 'STOP!', 'GO!', 'GO!', 'GO!', 'STOP!', 'STOP!', 'GO!']\n",
        "output_label = DataFrame(output_label, columns=['Decision'])\n",
        "\n",
        "def show_one_image(index):\n",
        "  cv2_imshow(input_data[index])\n",
        "\n",
        "class ObjectDetectionModel():\n",
        "  def __init__(self):\n",
        "    self.cfg = None\n",
        "    self.predictor = None\n",
        "  def fit(self, X, y, pretrained=True):\n",
        "    self.cfg = get_cfg()\n",
        "    # add project-specific config (e.g., TensorMask) here if you're not running a model in detectron2's core library\n",
        "    self.cfg.merge_from_file(model_zoo.get_config_file(\"COCO-PanopticSegmentation/panoptic_fpn_R_50_3x.yaml\"))\n",
        "    self.cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5  # set threshold for this model\n",
        "    # Find a model from detectron2's model zoo. You can use the https://dl.fbaipublicfiles... url as well\n",
        "    self.cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-PanopticSegmentation/panoptic_fpn_R_50_3x.yaml\")\n",
        "    self.predictor = DefaultPredictor(self.cfg)\n",
        "  def predict(self, image):\n",
        "    outputs = self.predictor(image)\n",
        "    return outputs\n",
        "  def show_image(self, outputs, image):\n",
        "    cv2_imshow(image)\n",
        "    v = Visualizer(image[:, :, ::-1], MetadataCatalog.get(self.cfg.DATASETS.TRAIN[0]), scale=1.2)\n",
        "    out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
        "    cv2_imshow(out.get_image()[:, :, ::-1])\n",
        "\n",
        "\n",
        "class ImageSegmentationModel():\n",
        "  def __init__(self):\n",
        "    self.cfg = None\n",
        "    self.predictor = None\n",
        "  def fit(self, X, y, pretrained=True):\n",
        "    self.cfg = get_cfg()\n",
        "    # add project-specific config (e.g., TensorMask) here if you're not running a model in detectron2's core library\n",
        "    self.cfg.merge_from_file(model_zoo.get_config_file(\"COCO-PanopticSegmentation/panoptic_fpn_R_50_3x.yaml\"))\n",
        "    # Find a model from detectron2's model zoo. You can use the https://dl.fbaipublicfiles... url as well\n",
        "    self.cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-PanopticSegmentation/panoptic_fpn_R_50_3x.yaml\")\n",
        "    self.predictor = DefaultPredictor(self.cfg)\n",
        "  def predict(self, image):\n",
        "    panoptic_seg, segments_info = self.predictor(image)[\"panoptic_seg\"]\n",
        "    return (panoptic_seg, segments_info)\n",
        "  def show_image(self, outputs, image):\n",
        "    panoptic_seg, segments_info = outputs\n",
        "    v = Visualizer(image[:, :, ::-1], MetadataCatalog.get(self.cfg.DATASETS.TRAIN[0]), scale=1.2)\n",
        "    out = v.draw_panoptic_seg_predictions(panoptic_seg.to(\"cpu\"), segments_info)\n",
        "    cv2_imshow(out.get_image()[:, :, ::-1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EAgUIdw5pW6n"
      },
      "source": [
        "# Exploring the Cityscapes Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oWcY7Aj57UN_"
      },
      "source": [
        "for i in range(5):\n",
        "  show_one_image(i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5CbpJf3u7q9S"
      },
      "source": [
        "**What sort of data are we working with? What kind of objects are captured in the data?**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sUNdT-tkOhId",
        "cellView": "form"
      },
      "source": [
        "#@title Select a target image and explore its segmentation map!\n",
        "def show_segmented_image(index):\n",
        "  cv2_imshow(input_data[index])\n",
        "  cv2_imshow(output_data[index])\n",
        "\n",
        "interact(show_segmented_image, index=IntSlider(min=0, max=199, step=1, value=0))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "otRoT1KdAMwp"
      },
      "source": [
        "### Exercise: Getting our data shape\n",
        "Please print out the **number of images**, along with the **height and width** of each image. Let's print out the shape of our output data too!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HH4o1BgcAJP7"
      },
      "source": [
        "input_num_images, input_height, input_width, _ = input_data.shape\n",
        "output_num_images, output_height, output_width, _ = output_data.shape\n",
        "\n",
        "### YOUR CODE HERE ###\n",
        "print(\"Number of Input Images in Dataset:\", ___)\n",
        "print(\"Height of Input Image(pixels):\", ___)\n",
        "print(\"Width of Input Image(pixels):\", ___)\n",
        "print()\n",
        "print(\"Number of Output Images in Dataset:\", ___)\n",
        "print(\"Height of Output Image(pixels):\", ___)\n",
        "print(\"Width of Output Image(pixels):\", ___)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XhRmm0TfK3po"
      },
      "source": [
        "**Discussion Question:** Why are the values for the input and output data shape the same?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vk4gID50K03a"
      },
      "source": [
        "# Creating an Object Detection Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vPdE5CvwqNAH"
      },
      "source": [
        "model = ObjectDetectionModel()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hh4hixNaQq18"
      },
      "source": [
        "### Step 2: Train your model!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a5R5xm7gRx6e"
      },
      "source": [
        "### YOUR CODE BEGINS HERE ###\n",
        "\n",
        "### YOUR CODE ENDS HERE ###"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ePU8daW0TgZC"
      },
      "source": [
        "### Step 3: Make Predictions using your Model!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YryAfBepadFW"
      },
      "source": [
        "selected_index = 124 # Choose any image in our dataset\n",
        "show_one_image(selected_index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NCeeidDUUTGs"
      },
      "source": [
        "image = input_data[selected_index]\n",
        "### YOUR CODE BEGINS HERE ###\n",
        "\n",
        "### YOUR CODE ENDS HERE ###"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pzj9TERRrWbG"
      },
      "source": [
        "### Step 4: Visualize our predictions!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "77EnLWbrrXu7"
      },
      "source": [
        "### YOUR CODE BEGINS HERE ###\n",
        "\n",
        "### YOUR CODE ENDS HERE ###"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tcmfCWjEUj9b",
        "cellView": "form"
      },
      "source": [
        "#@title Try your model on any image in our dataset\n",
        "def run_model(selected_index):\n",
        "  im = input_data[selected_index]\n",
        "  outputs = model.predict(im)\n",
        "\n",
        "  model.show_image(outputs, im)\n",
        "\n",
        "interact(run_model, selected_index=IntSlider(min=0, max=199, step=1, value=0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KB6yc1qbpkXe"
      },
      "source": [
        "### YOUR CODE BEGINS HERE ###\n",
        "\n",
        "### YOUR CODE ENDS HERE ###\n",
        "model.show_image(outputs, image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ujrBLfXrRXrf"
      },
      "source": [
        "#@title Run this to initialize output variables!\n",
        "output_instances = outputs[\"instances\"]\n",
        "pred_classes = output_instances.pred_classes.tolist()\n",
        "scores = output_instances.scores.tolist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M3ROaBY5RpiO"
      },
      "source": [
        "**Exercise:** Print out the output variables."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7d3KxiHO_0gb"
      },
      "source": [
        "print(scores)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KM_qkQl-IkV8"
      },
      "source": [
        "from google.colab import data_table\n",
        "\n",
        "data_table.DataTable(class_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fEBcR479fVzb"
      },
      "source": [
        "output_classes = ['class name 1', 'class name 2'] # Replace 'class name 1', 'class name 2', etc. with the class names from above"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sTZOMYnEKXvV"
      },
      "source": [
        "### Advanced Exercise: Write a for loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dQFuyA8SKU5p"
      },
      "source": [
        "output_classes = []\n",
        "### YOUR CODE BEGINS HERE ###\n",
        "\n",
        "### YOUR CODE ENDS HERE ###\n",
        "print(output_classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y7W1IqpSg--W"
      },
      "source": [
        "For now, we'll say that the car should stop given the following conditions:\n",
        "\n",
        "\n",
        "1.   If a bike is detected in the image, stop the car.\n",
        "2.   If a person is detected in the image, stop the car.\n",
        "3.   Otherwise, keep moving the car forward.\n",
        "\n",
        "Now let's code this up! You could imagine the function predict_movement() looking a little like this:\n",
        "\n",
        "```\n",
        "def predict_movement(pred_classes):\n",
        "  if(_____ in pred_classes):\n",
        "    return \"STOP!\"\n",
        "  else:\n",
        "    return \"GO!\"\n",
        "```\n",
        "\n",
        "**Discussion Question:** What values should we be putting into the blanks?\n",
        "\n",
        "Let's do some investigating and figure out which indexes correspond to a bike or a person so we can tell our car what to do!\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "Y5RSZ_DCjSFe"
      },
      "source": [
        "#@title Find out which class indexes are for bike and person\n",
        "def show_object_index(class_index):\n",
        "  return class_list['Class name'][class_index]\n",
        "\n",
        "interact(show_object_index, class_index=IntSlider(min=0, max=70, step=1, value=0))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nk7WdraBhaOW"
      },
      "source": [
        "def predict_movement(pred_classes):\n",
        "  if ______ in pred_classes:\n",
        "    return \"STOP!\"\n",
        "  #TODO: Add condition for bike and other objects here\n",
        "  else:\n",
        "    return \"GO!\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AfIpzG8eq3yY",
        "cellView": "form"
      },
      "source": [
        "#@title Run our decision-making model on images of your choice\n",
        "def run_decision_making_model(selected_index):\n",
        "  im = input_data[selected_index]\n",
        "  outputs = model.predict(im)\n",
        "\n",
        "  model.show_image(outputs, im)\n",
        "  output_instances = outputs[\"instances\"]\n",
        "  pred_classes = output_instances.pred_classes.tolist()\n",
        "\n",
        "  print(\"Final decision:\", predict_movement(pred_classes))\n",
        "interact(run_decision_making_model, selected_index=IntSlider(value=0, min=0, max=199, step=1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WSBQ2enayZH8"
      },
      "source": [
        "#@title Get Decision Model Accuracy! (may take a minute to run)\n",
        "predictions = []\n",
        "for image in tqdm(input_data):\n",
        "  outputs = model.predict(image)\n",
        "  output_instances = outputs[\"instances\"]\n",
        "  pred_classes = output_instances.pred_classes.tolist()\n",
        "\n",
        "  predictions.append(predict_movement(pred_classes))\n",
        "\n",
        "output_label['Predicted Decision'] = predictions\n",
        "\n",
        "print(\"\\nAccuracy:\", len([0 for i, pred in enumerate(predictions) if output_label['Decision'][i] == pred])/len(output_data))\n",
        "data_table.DataTable(output_label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F4MrlS1w0KRa",
        "cellView": "form"
      },
      "source": [
        "#@title Set up our crop boundary!\n",
        "\n",
        "left_crop_final = IntSlider(min=0, max=511, step=1, value=0)\n",
        "right_crop_final = IntSlider(min=0, max=511, step=1, value=511)\n",
        "bottom_crop_final = IntSlider(min=0, max=255, step=1, value=255)\n",
        "top_crop_final = IntSlider(min=0, max=255, step=1, value=0)\n",
        "\n",
        "def show_cropped_image(selected_index, left_crop, right_crop, bottom_crop, top_crop):\n",
        "  im = input_data[selected_index]\n",
        "  crop_img = im[top_crop:bottom_crop, left_crop:right_crop]\n",
        "  outputs = model.predict(crop_img)\n",
        "  model.show_image(outputs, crop_img)\n",
        "\n",
        "interact(show_cropped_image,\n",
        "         selected_index=IntSlider(min=0, max=199, step=1, value=0),\n",
        "         left_crop=left_crop_final,\n",
        "         right_crop=right_crop_final,\n",
        "         bottom_crop=bottom_crop_final,\n",
        "         top_crop=top_crop_final\n",
        "         )\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n9WtVwht5jKd",
        "cellView": "form"
      },
      "source": [
        "#@title Get Cropped Model Accuracy! (may take a minute to run)\n",
        "predictions = []\n",
        "for image in tqdm(input_data):\n",
        "  crop_img = image[top_crop_final.value:bottom_crop_final.value, left_crop_final.value:right_crop_final.value]\n",
        "  outputs = model.predict(crop_img)\n",
        "  output_instances = outputs[\"instances\"]\n",
        "  pred_classes = output_instances.pred_classes.tolist()\n",
        "\n",
        "  predictions.append(predict_movement(pred_classes))\n",
        "\n",
        "output_label['Predicted Decision'] = predictions\n",
        "print(\"\\nAccuracy:\", len([0 for i, pred in enumerate(predictions) if output_label['Decision'][i] == pred])/len(output_data))\n",
        "output_label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJRo2hTjzi3X",
        "cellView": "form"
      },
      "source": [
        "#@title Run this to view misclassified images!\n",
        "decision = output_label['Decision']\n",
        "pred_decision = output_label['Predicted Decision']\n",
        "misclassified = decision[pred_decision != decision]\n",
        "for i in range(10):\n",
        "  cv2_imshow(input_data[misclassified.index[i]])\n",
        "  print(\"Our Prediction: \", output_label['Predicted Decision'][misclassified.index[i]])\n",
        "  print(\"Correct Prediction: \", output_label['Decision'][misclassified.index[i]])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SujaoQW737JZ"
      },
      "source": [
        "seg_model = ImageSegmentationModel()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kxfFzXbI37Ja"
      },
      "source": [
        "### YOUR CODE HERE ###"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9PZW55HO37Jc"
      },
      "source": [
        "segment_index = 0 # Choose any image from our input data\n",
        "\n",
        "image = input_data[segment_index]\n",
        "### YOUR CODE BEGINS HERE ###\n",
        "\n",
        "### YOUR CODE ENDS HERE ###"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FCBXcKaZ37Jd"
      },
      "source": [
        "seg_model.show_image(outputs, image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bsbuMugW37Jd",
        "cellView": "form"
      },
      "source": [
        "#@title Try your model on any image from our data!\n",
        "def run_model(selected_index):\n",
        "  im = input_data[selected_index]\n",
        "  outputs = seg_model.predict(im)\n",
        "\n",
        "  seg_model.show_image(outputs, im)\n",
        "\n",
        "interact(run_model, selected_index=IntSlider(min=0, max=199, step=1, value=0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i3X02xS037Je"
      },
      "source": [
        "**Discussion Question**: What additional information does our Image Segmentation model provide compared to our Object Detection Model?"
      ]
    }
  ]
}